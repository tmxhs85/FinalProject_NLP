{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "SpYmdBucW5kY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpYmdBucW5kY",
        "outputId": "e86f12ba-aae2-4949-d938-bdb2c6588879"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.97\n"
          ]
        }
      ],
      "source": [
        "pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Qbn15tYxVET",
        "outputId": "cd2cd3c1-bce7-4f30-ffde-56ccc434e094"
      },
      "id": "_Qbn15tYxVET",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "b77e19ef-51da-443d-a1b7-c4e5516c1271",
      "metadata": {
        "id": "b77e19ef-51da-443d-a1b7-c4e5516c1271"
      },
      "outputs": [],
      "source": [
        "import sentencepiece as spm\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from random import random, randrange, randint, shuffle, choice\n",
        "from typing import Optional\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "from tqdm import tqdm, tqdm_notebook, trange\n",
        "import json\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "1c0916a0-5b51-476f-a48e-23381b43daa2",
      "metadata": {
        "id": "1c0916a0-5b51-476f-a48e-23381b43daa2"
      },
      "outputs": [],
      "source": [
        "corpus = \"/content/drive/MyDrive/WikiQA.txt\"\n",
        "prefix = \"WikiQA\"\n",
        "vocab_size = 12000\n",
        "spm.SentencePieceTrainer.train(\n",
        "    f\"--input={corpus} --model_prefix={prefix} --vocab_size={vocab_size + 7}\" + \n",
        "    \" --model_type=bpe\" +\n",
        "    \" --max_sentence_length=999999\" + # 문장 최대 길이\n",
        "    \" --pad_id=0 --pad_piece=[PAD]\" + # pad (0)\n",
        "    \" --unk_id=1 --unk_piece=[UNK]\" + # unknown (1)\n",
        "    \" --bos_id=2 --bos_piece=[BOS]\" + # begin of sequence (2)\n",
        "    \" --eos_id=3 --eos_piece=[EOS]\" + # end of sequence (3)\n",
        "    \" --user_defined_symbols=[SEP],[CLS],[MASK]\") # 사용자 정의 토큰"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "02d8a58c-3c7b-46c1-b4fb-c816f26ccdfa",
      "metadata": {
        "id": "02d8a58c-3c7b-46c1-b4fb-c816f26ccdfa",
        "outputId": "4827277d-c4f8-4e74-90bd-bad9cb5146b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i hydro you , i\n",
            "['▁i', '▁hydro', '▁you', '▁,', '▁i']\n",
            "[537, 1866, 1523, 32, 537]\n",
            "i hydro you , i\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'white'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "vocab_file = \"WikiQA.model\"\n",
        "vocab = spm.SentencePieceProcessor()\n",
        "vocab.load(vocab_file)\n",
        "\n",
        "lines = [\n",
        "  'i hydro you , i'\n",
        "]\n",
        "for line in lines:\n",
        "    pieces = vocab.encode_as_pieces(line)\n",
        "    ids = vocab.encode_as_ids(line)\n",
        "    a = vocab.Decode(ids)\n",
        "    print(line)\n",
        "    print(pieces)\n",
        "    print(ids)\n",
        "    print(a)\n",
        "    print()\n",
        "vocab.decode(1737)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "810133db-74e2-42a7-a0e6-716ae0e7ff45",
      "metadata": {
        "id": "810133db-74e2-42a7-a0e6-716ae0e7ff45"
      },
      "outputs": [],
      "source": [
        "  class Config(dict): \n",
        "    __getattr__ = dict.__getitem__\n",
        "    __setattr__ = dict.__setitem__\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, file):\n",
        "        with open(file, 'r') as f:\n",
        "            config = json.loads(f.read())\n",
        "            return Config(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "7bc51a3e-dbf9-4683-ad79-8f920257f809",
      "metadata": {
        "id": "7bc51a3e-dbf9-4683-ad79-8f920257f809",
        "outputId": "279e2e47-9ffb-4be1-e072-c3bdf28f664f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'n_enc_vocab': 12007, 'n_enc_seq': 256, 'n_seg_type': 2, 'n_layer': 12, 'd_hidn': 768, 'i_pad': 0, 'd_ff': 1024, 'n_head': 16, 'd_head': 48, 'dropout': 0.1, 'layer_norm_epsilon': 1e-12}\n"
          ]
        }
      ],
      "source": [
        "config = Config({\n",
        "    \"n_enc_vocab\": len(vocab),\n",
        "    \"n_enc_seq\": 256,\n",
        "    \"n_seg_type\": 2,\n",
        "    \"n_layer\": 12,\n",
        "    \"d_hidn\": 768,\n",
        "    \"i_pad\": 0,\n",
        "    \"d_ff\": 1024,\n",
        "    \"n_head\": 16,\n",
        "    \"d_head\": 48,\n",
        "    \"dropout\": 0.1,\n",
        "    \"layer_norm_epsilon\": 1e-12\n",
        "})\n",
        "print(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "9f7d2fb5-381c-45df-a12c-14bf985406a4",
      "metadata": {
        "id": "9f7d2fb5-381c-45df-a12c-14bf985406a4"
      },
      "outputs": [],
      "source": [
        "\"\"\" attention pad mask \"\"\"\n",
        "def get_attn_pad_mask(seq_q, seq_k, i_pad):\n",
        "    batch_size, len_q = seq_q.size()\n",
        "    batch_size, len_k = seq_k.size()\n",
        "    pad_attn_mask = seq_k.data.eq(i_pad).unsqueeze(1).expand(batch_size, len_q, len_k)  # \n",
        "    return pad_attn_mask\n",
        "\n",
        "\"\"\" scale dot product attention \"\"\"\n",
        "class ScaledDotProductAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "        self.scale = 1 / (self.config.d_head ** 0.5)\n",
        "    \n",
        "    def forward(self, Q, K, V, attn_mask):\n",
        "        # (bs, n_head, n_q_seq, n_k_seq)\n",
        "        scores = torch.matmul(Q, K.transpose(-1, -2)).mul_(self.scale)\n",
        "        scores.masked_fill_(attn_mask, -1e9)\n",
        "        # (bs, n_head, n_q_seq, n_k_seq)\n",
        "        attn_prob = nn.Softmax(dim=-1)(scores)\n",
        "        attn_prob = self.dropout(attn_prob)\n",
        "        # (bs, n_head, n_q_seq, d_v)\n",
        "        context = torch.matmul(attn_prob, V)\n",
        "        # (bs, n_head, n_q_seq, d_v), (bs, n_head, n_q_seq, n_v_seq)\n",
        "        return context, attn_prob\n",
        "\n",
        "\n",
        "\"\"\" multi head attention \"\"\"\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.W_Q = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n",
        "        self.W_K = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n",
        "        self.W_V = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n",
        "        self.scaled_dot_attn = ScaledDotProductAttention(self.config)\n",
        "        self.linear = nn.Linear(self.config.n_head * self.config.d_head, self.config.d_hidn)\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "    \n",
        "    def forward(self, Q, K, V, attn_mask):\n",
        "        batch_size = Q.size(0)\n",
        "        # (bs, n_head, n_q_seq, d_head)\n",
        "        q_s = self.W_Q(Q).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n",
        "        # (bs, n_head, n_k_seq, d_head)\n",
        "        k_s = self.W_K(K).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n",
        "        # (bs, n_head, n_v_seq, d_head)\n",
        "        v_s = self.W_V(V).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n",
        "\n",
        "        # (bs, n_head, n_q_seq, n_k_seq)\n",
        "        attn_mask = attn_mask.unsqueeze(1).repeat(1, self.config.n_head, 1, 1)\n",
        "\n",
        "        # (bs, n_head, n_q_seq, d_head), (bs, n_head, n_q_seq, n_k_seq)\n",
        "        context, attn_prob = self.scaled_dot_attn(q_s, k_s, v_s, attn_mask)\n",
        "        # (bs, n_head, n_q_seq, h_head * d_head)\n",
        "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.config.n_head * self.config.d_head)\n",
        "        # (bs, n_head, n_q_seq, e_embd)\n",
        "        output = self.linear(context)\n",
        "        output = self.dropout(output)\n",
        "        # (bs, n_q_seq, d_hidn), (bs, n_head, n_q_seq, n_k_seq)\n",
        "        return output, attn_prob\n",
        "\n",
        "\n",
        "\"\"\" feed forward \"\"\"\n",
        "class PoswiseFeedForwardNet(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.conv1 = nn.Conv1d(in_channels=self.config.d_hidn, out_channels=self.config.d_ff, kernel_size=1)\n",
        "        self.conv2 = nn.Conv1d(in_channels=self.config.d_ff, out_channels=self.config.d_hidn, kernel_size=1)\n",
        "        # self.w_1 = nn.Linear(self.config.d_hidn, self.config.d_ff)\n",
        "        # self.w_2 = nn.Linear(self.config.d_ff, self.config.d_hidn)\n",
        "        self.active = F.gelu\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # (bs, d_ff, n_seq)\n",
        "        output = self.active(self.conv1(inputs.transpose(1, 2)))\n",
        "        # (bs, n_seq, d_hidn)\n",
        "        output = self.conv2(output).transpose(1, 2)\n",
        "        output = self.dropout(output)\n",
        "        # (bs, n_seq, d_hidn)\n",
        "        return output\n",
        "        # return self.w_2(self.dropout(self.active(self.w_1(inputs))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "d23a53de-22c1-4ff5-9033-6817421b9747",
      "metadata": {
        "id": "d23a53de-22c1-4ff5-9033-6817421b9747"
      },
      "outputs": [],
      "source": [
        "\"\"\" encoder layer \"\"\"\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.self_attn = MultiHeadAttention(self.config)\n",
        "        self.layer_norm1 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n",
        "        self.pos_ffn = PoswiseFeedForwardNet(self.config)\n",
        "        self.layer_norm2 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n",
        "    \n",
        "    def forward(self, inputs, attn_mask):\n",
        "        # (bs, n_enc_seq, d_hidn), (bs, n_head, n_enc_seq, n_enc_seq)\n",
        "        att_outputs, attn_prob = self.self_attn(inputs, inputs, inputs, attn_mask)\n",
        "        att_outputs = self.layer_norm1(inputs + att_outputs)\n",
        "        # (bs, n_enc_seq, d_hidn)\n",
        "        ffn_outputs = self.pos_ffn(att_outputs)\n",
        "        ffn_outputs = self.layer_norm2(ffn_outputs + att_outputs)\n",
        "        # (bs, n_enc_seq, d_hidn), (bs, n_head, n_enc_seq, n_enc_seq)\n",
        "        return ffn_outputs, attn_prob\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "00340d71-bf04-4f6d-ae91-d0856c5c43e3",
      "metadata": {
        "id": "00340d71-bf04-4f6d-ae91-d0856c5c43e3"
      },
      "outputs": [],
      "source": [
        "\"\"\" encoder \"\"\"\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.enc_emb = nn.Embedding(self.config.n_enc_vocab, self.config.d_hidn)\n",
        "        self.pos_emb = nn.Embedding(self.config.n_enc_seq + 1, self.config.d_hidn)\n",
        "        self.seg_emb = nn.Embedding(self.config.n_seg_type, self.config.d_hidn)\n",
        "\n",
        "        self.layers = nn.ModuleList([EncoderLayer(self.config) for _ in range(self.config.n_layer)])\n",
        "    \n",
        "    def forward(self, inputs, segments):\n",
        "        positions = torch.arange(inputs.size(1), device=inputs.device, dtype=inputs.dtype).expand(inputs.size(0), inputs.size(1)).contiguous() + 1\n",
        "        pos_mask = inputs.eq(self.config.i_pad)\n",
        "        positions.masked_fill_(pos_mask, 0)\n",
        "\n",
        "        # (bs, n_enc_seq, d_hidn)\n",
        "        outputs = self.enc_emb(inputs) + self.pos_emb(positions)  + self.seg_emb(segments)\n",
        "\n",
        "        # (bs, n_enc_seq, n_enc_seq)\n",
        "        attn_mask = get_attn_pad_mask(inputs, inputs, self.config.i_pad)\n",
        "\n",
        "        attn_probs = []\n",
        "        for layer in self.layers:\n",
        "            # (bs, n_enc_seq, d_hidn), (bs, n_head, n_enc_seq, n_enc_seq)\n",
        "            outputs, attn_prob = layer(outputs, attn_mask)\n",
        "            attn_probs.append(attn_prob)\n",
        "        # (bs, n_enc_seq, d_hidn), [(bs, n_head, n_enc_seq, n_enc_seq)]\n",
        "        return outputs, attn_probs\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "2e3db27c-3e6d-4479-8c5d-fa5d64b4b3aa",
      "metadata": {
        "id": "2e3db27c-3e6d-4479-8c5d-fa5d64b4b3aa"
      },
      "outputs": [],
      "source": [
        "class BERT(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.encoder = Encoder(self.config)\n",
        "\n",
        "        self.linear = nn.Linear(config.d_hidn, config.d_hidn)\n",
        "        self.activation = torch.tanh\n",
        "    \n",
        "    def forward(self, inputs, segments):\n",
        "        # (bs, n_seq, d_hidn), [(bs, n_head, n_enc_seq, n_enc_seq)]\n",
        "        outputs, self_attn_probs = self.encoder(inputs, segments)\n",
        "        # (bs, d_hidn)\n",
        "        outputs_cls = outputs[:, 0].contiguous()\n",
        "        outputs_cls = self.linear(outputs_cls)\n",
        "        outputs_cls = self.activation(outputs_cls)\n",
        "        # (bs, n_enc_seq, n_enc_vocab), (bs, d_hidn), [(bs, n_head, n_enc_seq, n_enc_seq)]\n",
        "        return outputs, outputs_cls, self_attn_probs\n",
        "    \n",
        "    def save(self, epoch, loss, path):\n",
        "        torch.save({\n",
        "            \"epoch\": epoch,\n",
        "            \"loss\": loss,\n",
        "            \"state_dict\": self.state_dict()\n",
        "        }, path)\n",
        "    \n",
        "    def load(self, path):\n",
        "        save = torch.load(path)\n",
        "        self.load_state_dict(save[\"state_dict\"])\n",
        "        return save[\"epoch\"], save[\"loss\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "a38d73b8-9444-4a42-954a-64d989b274c9",
      "metadata": {
        "id": "a38d73b8-9444-4a42-954a-64d989b274c9"
      },
      "outputs": [],
      "source": [
        "\"\"\" BERT pretrain \"\"\"\n",
        "class BERTPretrain(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.bert = BERT(self.config)\n",
        "        # classfier\n",
        "        self.projection_cls = nn.Linear(self.config.d_hidn, 2, bias=False)\n",
        "        # lm\n",
        "        self.projection_lm = nn.Linear(self.config.d_hidn, self.config.n_enc_vocab, bias=False)\n",
        "        self.projection_lm.weight = self.bert.encoder.enc_emb.weight\n",
        "        self.softmax = nn.LogSoftmax(dim=-1)\n",
        "    \n",
        "    def forward(self, inputs, segments):\n",
        "        # (bs, n_enc_seq, d_hidn), (bs, d_hidn), [(bs, n_head, n_enc_seq, n_enc_seq)]\n",
        "        outputs, outputs_cls, attn_probs = self.bert(inputs, segments)\n",
        "        # (bs, 2)\n",
        "        logits_cls = self.projection_cls(outputs_cls)\n",
        "        # logits_cls = self.softmax(logits_cls)\n",
        "        # (bs, n_enc_seq, n_enc_vocab)\n",
        "        logits_lm = self.projection_lm(outputs)\n",
        "        # logits_lm = self.softmax(logits_lm)\n",
        "        # (bs, n_enc_vocab), (bs, n_enc_seq, n_enc_vocab), [(bs, n_head, n_enc_seq, n_enc_seq)]\n",
        "        return logits_cls, logits_lm, attn_probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "f12fc65e-758e-4653-9253-cd7368479f4c",
      "metadata": {
        "id": "f12fc65e-758e-4653-9253-cd7368479f4c"
      },
      "outputs": [],
      "source": [
        "\"\"\" 마스크 생성 \"\"\"\n",
        "def create_pretrain_mask(tokens, mask_cnt, vocab_list):\n",
        "    cand_idx = []\n",
        "    for (i, token) in enumerate(tokens):\n",
        "        if token == \"[CLS]\" or token == \"[SEP]\":\n",
        "            continue\n",
        "        if 0 < len(cand_idx) and not token.startswith(u\"\\u2581\"):\n",
        "            cand_idx[-1].append(i)\n",
        "        else:\n",
        "            cand_idx.append([i])\n",
        "    shuffle(cand_idx)\n",
        "\n",
        "    mask_lms = []\n",
        "    for index_set in cand_idx:\n",
        "        if len(mask_lms) >= mask_cnt:\n",
        "            break\n",
        "        if len(mask_lms) + len(index_set) > mask_cnt:\n",
        "            continue\n",
        "        for index in index_set:\n",
        "            masked_token = None\n",
        "            if random() < 0.8: # 80% replace with [MASK]\n",
        "                masked_token = \"[MASK]\"\n",
        "            else:\n",
        "                if random() < 0.5: # 10% keep original\n",
        "                    masked_token = tokens[index]\n",
        "                else: # 10% random word\n",
        "                    masked_token = choice(vocab_list)\n",
        "            mask_lms.append({\"index\": index, \"label\": tokens[index]})\n",
        "            tokens[index] = masked_token\n",
        "    mask_lms = sorted(mask_lms, key=lambda x: x[\"index\"])\n",
        "    mask_idx = [p[\"index\"] for p in mask_lms]\n",
        "    mask_label = [p[\"label\"] for p in mask_lms]\n",
        "\n",
        "    return tokens, mask_idx, mask_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "8ab2ddff-73e1-4732-bdd1-0615492bff01",
      "metadata": {
        "id": "8ab2ddff-73e1-4732-bdd1-0615492bff01"
      },
      "outputs": [],
      "source": [
        "def trim_tokens(tokens_a, tokens_b, max_seq):\n",
        "    while True:\n",
        "        total_length = len(tokens_a) + len(tokens_b)\n",
        "        if total_length <= max_seq:\n",
        "            break\n",
        "\n",
        "        if len(tokens_a) > len(tokens_b):\n",
        "            del tokens_a[0]\n",
        "        else:\n",
        "            tokens_b.pop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "3d61812f-9c78-40ff-8fc9-05209b621a51",
      "metadata": {
        "id": "3d61812f-9c78-40ff-8fc9-05209b621a51"
      },
      "outputs": [],
      "source": [
        "\"\"\" doc별 pretrain 데이터 생성 \"\"\"\n",
        "def create_pretrain_instances(docs, doc_idx, doc, n_seq, mask_prob, vocab_list):\n",
        "    # for CLS], [SEP], [SEP]\n",
        "    max_seq = n_seq - 3\n",
        "    tgt_seq = max_seq\n",
        "    \n",
        "    instances = []\n",
        "    current_chunk = []\n",
        "    current_length = 0\n",
        "    a_end=1\n",
        "    for i in range(len(doc)):\n",
        "        current_chunk.append(doc[i]) # line\n",
        "        current_length += len(doc[i])\n",
        "    for i in range(len(current_chunk)):\n",
        "        if current_chunk[i] =='▁,':\n",
        "            a_end=i\n",
        "    tokens_a = doc[:a_end]\n",
        "    tokens_b = doc[a_end+1: ]\n",
        "   \n",
        "    is_next = 1\n",
        "    \n",
        "    if random() < 0.5:\n",
        "        is_next = 0\n",
        "        tokens_b = []\n",
        "        tokens_b_len = tgt_seq - len(tokens_a)\n",
        "        random_doc_idx = 0\n",
        "        while True:\n",
        "            random_doc_idx = randrange(0, len(docs))\n",
        "            if random_doc_idx != doc_idx:\n",
        "              break\n",
        "        random_doc = docs[random_doc_idx]\n",
        "\n",
        "        random_start = randrange(0, len(random_doc))\n",
        "        for j in range(random_start, len(random_doc)):\n",
        "            tokens_b.append(random_doc[j])\n",
        "    \n",
        "    \n",
        "    \n",
        "    trim_tokens(tokens_a, tokens_b, max_seq)\n",
        "    if len(tokens_b) > 0 and len(tokens_a) > 0:\n",
        "        tokens = [\"[CLS]\"] + tokens_a + [\"[SEP]\"] + tokens_b + [\"[SEP]\"]\n",
        "        segment = [0] * (len(tokens_a) + 2) + [1] * (len(tokens_b) + 1)\n",
        "\n",
        "        tokens, mask_idx, mask_label = create_pretrain_mask(tokens, int((len(tokens) - 3) * mask_prob), vocab_list)\n",
        "\n",
        "        instance = {\n",
        "            \"tokens\": tokens,\n",
        "            \"segment\": segment,\n",
        "            \"is_next\": is_next,\n",
        "            \"mask_idx\": mask_idx,\n",
        "            \"mask_label\": mask_label\n",
        "        }\n",
        "        instances.append(instance)\n",
        "        current_chunk = []\n",
        "        current_length = 0\n",
        "\n",
        "        # if i == len(doc) - 1 or current_length >= tgt_seq:\n",
        "        #     if 0 < len(current_chunk):                    \n",
        "        #         a_end = 1\n",
        "        #         if 1 < len(current_chunk):\n",
        "        #             a_end = randrange(1, len(current_chunk))\n",
        "        #         tokens_a = []\n",
        "        #         for j in range(a_end):\n",
        "        #             tokens_a.append(current_chunk[j])\n",
        "                \n",
        "        #         tokens_b = []\n",
        "        #         if len(current_chunk) == 1 or random() < 0.5:\n",
        "        #             is_next = 0\n",
        "        #             tokens_b_len = tgt_seq - len(tokens_a)\n",
        "        #             random_doc_idx = doc_idx\n",
        "        #             while doc_idx == random_doc_idx:\n",
        "        #                 random_doc_idx = randrange(0, len(docs))\n",
        "        #             random_doc = docs[random_doc_idx]\n",
        "\n",
        "        #             random_start = randrange(0, len(random_doc))\n",
        "        #             for j in range(random_start, len(random_doc)):\n",
        "        #                 tokens_b.append(random_doc[j])\n",
        "        #         else:\n",
        "        #             is_next = 1\n",
        "        #             for j in range(a_end, len(current_chunk)):\n",
        "        #                 tokens_b.append(current_chunk[j])\n",
        "\n",
        "        #         trim_tokens(tokens_a, tokens_b, max_seq)\n",
        "        #         assert 0 < len(tokens_a)\n",
        "        #         assert 0 < len(tokens_b)\n",
        "\n",
        "        #         tokens = [\"[CLS]\"] + tokens_a + [\"[SEP]\"] + tokens_b + [\"[SEP]\"]\n",
        "        #         segment = [0] * (len(tokens_a) + 2) + [1] * (len(tokens_b) + 1)\n",
        "\n",
        "        #         tokens, mask_idx, mask_label = create_pretrain_mask(tokens, int((len(tokens) - 3) * mask_prob), vocab_list)\n",
        "\n",
        "        #         instance = {\n",
        "        #             \"tokens\": tokens,\n",
        "        #             \"segment\": segment,\n",
        "        #             \"is_next\": is_next,\n",
        "        #             \"mask_idx\": mask_idx,\n",
        "        #             \"mask_label\": mask_label\n",
        "        #         }\n",
        "        #         instances.append(instance)\n",
        "        #     current_chunk = []\n",
        "        #     current_length = 0\n",
        "    return instances  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "4529ce4b-98f5-4120-bb87-a2ccf3b71951",
      "metadata": {
        "id": "4529ce4b-98f5-4120-bb87-a2ccf3b71951"
      },
      "outputs": [],
      "source": [
        "def make_pretrain_data(vocab, in_file, out_file, count, n_seq, mask_prob):\n",
        "    vocab_list = []\n",
        "    for id in range(vocab.get_piece_size()):\n",
        "        if not vocab.is_unknown(id):\n",
        "            vocab_list.append(vocab.id_to_piece(id))\n",
        "\n",
        "    line_cnt = 0\n",
        "    with open(in_file, \"r\", encoding='UTF8') as in_f:\n",
        "        for line in in_f:\n",
        "            line_cnt += 1\n",
        "    docs = []\n",
        "    with open(in_file, \"r\", encoding='UTF8') as f:\n",
        "        doc = []\n",
        "        with tqdm(total=line_cnt, desc=f\"Loading\") as pbar:\n",
        "            for i, line in enumerate(f):\n",
        "                line = line.strip()\n",
        "                if line == \"\":\n",
        "                    if 0 < len(doc):\n",
        "                        docs.append(doc)\n",
        "                        doc = []\n",
        "                        # 메모리 사용량을 줄이기 위해 100,000개만 처리 함\n",
        "                        if 100000 < len(docs): break\n",
        "                else:\n",
        "                    pieces = vocab.encode_as_pieces(line)\n",
        "                    if 0 < len(pieces):\n",
        "                        doc.append(pieces)\n",
        "                pbar.update(1)\n",
        "        if doc:\n",
        "            docs.append(doc)\n",
        "    docs = sum(docs,[])\n",
        "    for index in range(count):\n",
        "        output = out_file.format(index)\n",
        "        # if os.path.isfile(output): continue\n",
        "        \n",
        "        with open(output, \"w\", encoding='UTF8') as out_f:\n",
        "            with tqdm(total=len(docs), desc=f\"Making\") as pbar:\n",
        "                for i, doc in enumerate(docs):\n",
        "                    instances = create_pretrain_instances(docs, i, doc, n_seq, mask_prob, vocab_list)\n",
        "                    for instance in instances:\n",
        "                        print(instance, file=out_f)\n",
        "                        # out_f.write(instance)\n",
        "                        # out_f.write(\"\\n\")\n",
        "                    pbar.update(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "aa202de2-de8b-4ae4-b969-f0235b3b44e0",
      "metadata": {
        "id": "aa202de2-de8b-4ae4-b969-f0235b3b44e0",
        "tags": [],
        "outputId": "31f57ad6-8d03-438e-a804-6c9f49a6c7f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading: 100%|██████████| 63282/63282 [00:06<00:00, 9179.91it/s]\n",
            "Making: 100%|██████████| 63282/63282 [00:03<00:00, 18813.62it/s]\n"
          ]
        }
      ],
      "source": [
        "in_file = \"/content/drive/MyDrive/WikiQA.txt\"\n",
        "out_file = \"WikiQA_{}.json\"\n",
        "count = 1\n",
        "n_seq = 256\n",
        "mask_prob = 0.15\n",
        "\n",
        "make_pretrain_data(vocab, in_file, out_file, count, n_seq, mask_prob)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "ec1a6477-b2a8-4347-94fd-71ce2e52dc20",
      "metadata": {
        "id": "ec1a6477-b2a8-4347-94fd-71ce2e52dc20"
      },
      "outputs": [],
      "source": [
        "class PretrainDataSet(torch.utils.data.Dataset):\n",
        "    def __init__(self, vocab, infile):\n",
        "        self.vocab = vocab\n",
        "        self.labels_cls = []\n",
        "        self.labels_lm = []\n",
        "        self.sentences = []\n",
        "        self.segments = []\n",
        "    \n",
        "        line_cnt = 0\n",
        "        with open(infile, \"r\", encoding=\"UTF8\") as f:\n",
        "            for line in f:\n",
        "                line_cnt += 1\n",
        "\n",
        "        with open(infile, \"r\",encoding=\"UTF8\") as f:\n",
        "            for i, line in enumerate(tqdm(f, total=line_cnt, desc=f\"Loading {infile}\", unit=\" lines\")):\n",
        "                line = json.dumps(line)\n",
        "                instance = eval(json.loads(line))\n",
        "                self.labels_cls.append(instance['is_next'])\n",
        "                sentences = [vocab.piece_to_id(p) for p in instance[\"tokens\"]]\n",
        "                self.sentences.append(sentences)\n",
        "                self.segments.append(instance[\"segment\"])\n",
        "                mask_idx = np.array(instance[\"mask_idx\"], dtype=np.int64)\n",
        "                mask_label = np.array([vocab.piece_to_id(p) for p in instance[\"mask_label\"]], dtype=np.int64)\n",
        "                label_lm = np.full(len(sentences), dtype=np.int64, fill_value=-1)\n",
        "                label_lm[mask_idx] = mask_label\n",
        "                self.labels_lm.append(label_lm)\n",
        "    \n",
        "    def __len__(self):\n",
        "        assert len(self.labels_cls) == len(self.labels_lm)\n",
        "        assert len(self.labels_cls) == len(self.sentences)\n",
        "        assert len(self.labels_cls) == len(self.segments)\n",
        "        return len(self.labels_cls)\n",
        "    \n",
        "    def __getitem__(self, item):\n",
        "        return (torch.tensor(self.labels_cls[item]),\n",
        "                torch.tensor(self.labels_lm[item]),\n",
        "                torch.tensor(self.sentences[item]),\n",
        "                torch.tensor(self.segments[item]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "544c4393-d179-4bfa-b55f-fc91d1c0afa9",
      "metadata": {
        "id": "544c4393-d179-4bfa-b55f-fc91d1c0afa9"
      },
      "outputs": [],
      "source": [
        "\"\"\" pretrain data collate_fn \"\"\"\n",
        "def pretrin_collate_fn(inputs):\n",
        "    labels_cls, labels_lm, inputs, segments = list(zip(*inputs))\n",
        "\n",
        "    labels_lm = torch.nn.utils.rnn.pad_sequence(labels_lm, batch_first=True, padding_value=0)\n",
        "    inputs = torch.nn.utils.rnn.pad_sequence(inputs, batch_first=True, padding_value=0)\n",
        "    segments = torch.nn.utils.rnn.pad_sequence(segments, batch_first=True, padding_value=0)\n",
        "   \n",
        "    batch = [\n",
        "        torch.stack(labels_cls, dim=0),\n",
        "        labels_lm,\n",
        "        inputs,\n",
        "        segments\n",
        "    ]\n",
        "    return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "99c641ab-c272-4439-a13e-eeb669418c8f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99c641ab-c272-4439-a13e-eeb669418c8f",
        "outputId": "dfcf27a6-4728-44d7-db12-f831593cc443"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading WikiQA_0.json: 100%|██████████| 63281/63281 [00:12<00:00, 5243.39 lines/s]\n"
          ]
        }
      ],
      "source": [
        "\"\"\" pretrain 데이터 로더 \"\"\"\n",
        "batch_size = 64\n",
        "dataset = PretrainDataSet(vocab, \"WikiQA_0.json\")\n",
        "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, collate_fn=pretrin_collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "11c3b51c-95a6-40e9-bc5b-cc30b61301c1",
      "metadata": {
        "id": "11c3b51c-95a6-40e9-bc5b-cc30b61301c1"
      },
      "outputs": [],
      "source": [
        "# def train_epoch_nsp(config, epoch, model, criterion_cls, optimizer, train_loader):\n",
        "#     losses = []\n",
        "#     model.train()\n",
        "#     with tqdm(total=len(train_loader), desc=f\"Train({epoch})\") as pbar:\n",
        "#         for i, value in enumerate(train_loader):\n",
        "#             labels_cls, labels_lm, inputs, segments = map(lambda v: v.to(config.device), value)\n",
        "#             optimizer.zero_grad()\n",
        "#             outputs = model(inputs, segments)\n",
        "#             logits_cls = outputs[0]\n",
        "        \n",
        "#             loss_cls = criterion_cls(logits_cls, labels_cls)\n",
        "            \n",
        "            \n",
        "\n",
        "#             losses.append(loss_cls)\n",
        "    \n",
        "#             loss_cls.backward()\n",
        "#             optimizer.step()\n",
        "\n",
        "#             pbar.update(1)\n",
        "#             pbar.set_postfix_str(f\"Loss: {loss_cls:.3f} ({np.mean(losses):.3f})\")\n",
        "#     return np.mean(losses)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch_mlm(config, epoch, model, criterion_lm, optimizer, train_loader):\n",
        "    losses = []\n",
        "    model.train()\n",
        "    with tqdm(total=len(train_loader), desc=f\"Train({epoch})\") as pbar:\n",
        "        for i, value in enumerate(train_loader):\n",
        "            labels_cls, labels_lm, inputs, segments = map(lambda v: v.to(config.device), value)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs, segments)\n",
        "            logits_lm =  outputs[1]\n",
        "        \n",
        "            loss_lm = criterion_lm(logits_lm.view(-1, logits_lm.size(2)), labels_lm.view(-1))\n",
        "\n",
        "            loss_val = loss_lm.item()\n",
        "            losses.append(loss_val)\n",
        "    \n",
        "            loss_lm.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            pbar.update(1)\n",
        "            pbar.set_postfix_str(f\"Loss: {loss_val:.3f} ({np.mean(losses):.3f})\")\n",
        "    return np.mean(losses)"
      ],
      "metadata": {
        "id": "7n6NkLAql_Ou"
      },
      "id": "7n6NkLAql_Ou",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "0217853d-b921-4e66-8acb-88f377a6485f",
      "metadata": {
        "id": "0217853d-b921-4e66-8acb-88f377a6485f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1c8b44d-6f77-4a68-da6d-9a9625c6d227"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'n_enc_vocab': 12007, 'n_enc_seq': 256, 'n_seg_type': 2, 'n_layer': 12, 'd_hidn': 768, 'i_pad': 0, 'd_ff': 1024, 'n_head': 16, 'd_head': 48, 'dropout': 0.1, 'layer_norm_epsilon': 1e-12, 'device': device(type='cuda')}\n"
          ]
        }
      ],
      "source": [
        "config.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(config)\n",
        "\n",
        "learning_rate = 1e-4\n",
        "betas=(0.9, 0.999)\n",
        "weight_decay = 0.01\n",
        "n_epoch = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "3ca17713-aa84-45c6-ac18-dfcf449d2bd3",
      "metadata": {
        "id": "3ca17713-aa84-45c6-ac18-dfcf449d2bd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44e5f7c0-5829-4724-ea6a-9520096296df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load pretrain from: save_bert_pretrain.pth, epoch=49, loss=0.6201690233061118\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train(50): 100%|██████████| 989/989 [02:21<00:00,  6.97it/s, Loss: 0.410 (0.621)]\n"
          ]
        }
      ],
      "source": [
        "model = BERTPretrain(config)\n",
        "\n",
        "save_pretrain = \"save_bert_pretrain.pth\"\n",
        "best_epoch, best_loss = 0, 0\n",
        "if os.path.isfile(save_pretrain):\n",
        "    best_epoch, best_loss = model.bert.load(save_pretrain)\n",
        "    print(f\"load pretrain from: {save_pretrain}, epoch={best_epoch}, loss={best_loss}\")\n",
        "    best_epoch += 1\n",
        "\n",
        "model.to(config.device)\n",
        "\n",
        "criterion_lm = torch.nn.CrossEntropyLoss(ignore_index=-1, reduction='mean')\n",
        "criterion_cls = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# losses = []\n",
        "# offset = best_epoch\n",
        "# for step in range(n_epoch):\n",
        "#     epoch = step + offset\n",
        "#     loss= train_epoch_nsp(config, epoch, model,criterion_cls optimizer, train_loader)\n",
        "#     losses.append(loss)\n",
        "#     model.bert.save(epoch, loss, save_pretrain)\n",
        "\n",
        "losses = []\n",
        "offset = best_epoch\n",
        "for step in range(n_epoch):\n",
        "    epoch = step + offset\n",
        "    loss= train_epoch_mlm(config, epoch, model, criterion_lm, optimizer, train_loader)\n",
        "    losses.append(loss)\n",
        "    model.bert.save(epoch, loss, save_pretrain)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f58f4628",
      "metadata": {
        "id": "f58f4628"
      },
      "source": [
        "#### Mask 예측 Test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_inputs = vocab.encode('how long is the term for federal[MASK] , In the United States  the title of federal judge usually means a judge appointed by the President of the United States and confirmed by the United States Senate pursuant to the Appointments Clause in Article II of the United States Constitution')\n",
        "test_inputs = torch.tensor([test_inputs]).to(config.device)\n",
        "test_segments = torch.zeros(len(test_inputs), dtype=int).to(config.device)\n",
        "model.eval()\n",
        "out = model(test_inputs, test_segments)\n",
        "[vocab.decode(i) for i in out[1].argmax(2).cpu().detach().tolist()]"
      ],
      "metadata": {
        "id": "Qb39Btw_LoEN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5660740-b554-42c4-ff09-9e1788f38642"
      },
      "id": "Qb39Btw_LoEN",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is']"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab.encode('[MASK]')\n",
        "vocab.decode(0)"
      ],
      "metadata": {
        "id": "5C28g6-u-ZJ0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "998d32b5-4d1b-4985-e521-2ff363ed3a01"
      },
      "id": "5C28g6-u-ZJ0",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_segments = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,0,0,0,0,0, 1, 1, 1, 1, 1, 1,1,1]\n",
        "test_segments = torch.tensor(test_segments).to(config.device)"
      ],
      "metadata": {
        "id": "-dBwogs8MPnQ"
      },
      "id": "-dBwogs8MPnQ",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_inputs.shape, test_segments.shape"
      ],
      "metadata": {
        "id": "R_ll-SSSNFld",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c44af187-9ce4-4404-b8b6-812167632719"
      },
      "id": "R_ll-SSSNFld",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 55]), torch.Size([30]))"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "out = model(test_inputs, test_segments)\n",
        "[vocab.decode(i) for i in out[1].argmax(2).cpu().detach().tolist()]"
      ],
      "metadata": {
        "id": "L2b8Io7XMQFH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1815f3a8-cbbb-498b-deed-f46adbaabfde"
      },
      "id": "L2b8Io7XMQFH",
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is',\n",
              " 'is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is',\n",
              " 'is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is',\n",
              " 'is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is',\n",
              " 'is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is',\n",
              " 'is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is',\n",
              " 'is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is',\n",
              " 'is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is',\n",
              " 'is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is',\n",
              " 'is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is',\n",
              " 'is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is',\n",
              " 'is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is',\n",
              " 'is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is',\n",
              " 'is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is',\n",
              " 'is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is',\n",
              " 'is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is',\n",
              " 'is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is',\n",
              " 'is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is',\n",
              " 'is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is',\n",
              " 'is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is',\n",
              " 'is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is',\n",
              " 'is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is',\n",
              " 'is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is',\n",
              " 'is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is',\n",
              " 'is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is',\n",
              " 'is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is',\n",
              " 'is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is',\n",
              " 'is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is',\n",
              " 'is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is',\n",
              " 'is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is',\n",
              " 'is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is',\n",
              " 'is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is is']"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "d3722152",
      "metadata": {
        "id": "d3722152"
      },
      "outputs": [],
      "source": [
        "test_sentence = '[CLS] what are your hobbies [SEP] i have been watching and playing [MASK] more than ten years , so that both are my hobbies'\n",
        "mask_idx1 = 13\n",
        "sentence1 = 'what are your hobbies'\n",
        "sentence2 = 'i have been watching and playing'\n",
        "sentence3 = 'more than ten years , so that both are my hobbies'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "5dcb5295",
      "metadata": {
        "id": "5dcb5295"
      },
      "outputs": [],
      "source": [
        "test_input1 = [5]\n",
        "for i in sentence1.split(' '):\n",
        "    test_input1 += vocab.Encode(i)\n",
        "test_input1 += [4]\n",
        "for i in sentence2.split(' '):\n",
        "    test_input1 += vocab.Encode(i)\n",
        "test_input1 += [6]\n",
        "for i in sentence3.split(' '):\n",
        "    test_input1 += vocab.Encode(i)\n",
        "test_input1 += [4]\n",
        "test_input1 += ([0] * (61 - len(test_input1)))\n",
        "test_input1 = torch.tensor(test_input1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "95a7bc46",
      "metadata": {
        "id": "95a7bc46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43e5b689-c758-4ba6-e0fb-731ccb4ad067"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([    5,    51,    97,  3518,    46,   394, 11967,   121,     4,   537,\n",
              "          258,   366,  2966,  6386,    42,  4129,     6,   445,   507,  2109,\n",
              "          627,    32,   707,   160,   787,    97,  1520,    46,   394, 11967,\n",
              "          121,     4,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "test_input1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "cf44ec2a",
      "metadata": {
        "id": "cf44ec2a"
      },
      "outputs": [],
      "source": [
        "test_segment1 = torch.tensor([0]*6 + [1]*18 + [0]*37)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "1825f7c4",
      "metadata": {
        "id": "1825f7c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "daaf558a-c750-4ca1-a3a0-6b7aa92653e3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "test_segment1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "12a06454",
      "metadata": {
        "id": "12a06454"
      },
      "outputs": [],
      "source": [
        "test_sentence = '[CLS] what is your greatest strength [SEP] i have been working hard in the biology field for about thirty years , that is why i can [MASK] saying that diligence is my greatest strength'\n",
        "mask_idx2 = 26\n",
        "sentence1 = 'what is your greatest strength'\n",
        "sentence2 = 'i have been working hard in the biology field for about thirty years , that is why i can'\n",
        "sentence3 = 'saying that diligence is my greatest strength'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "bda894fd",
      "metadata": {
        "id": "bda894fd"
      },
      "outputs": [],
      "source": [
        "test_input2 = [5]\n",
        "for i in sentence1.split(' '):\n",
        "    test_input2 += vocab.Encode(i)\n",
        "test_input2 += [4]\n",
        "for i in sentence2.split(' '):\n",
        "    test_input2 += vocab.Encode(i)\n",
        "test_input2 += [6]\n",
        "for i in sentence3.split(' '):\n",
        "    test_input2 += vocab.Encode(i)\n",
        "test_input2 += ([0] * (61 - len(test_input2)))\n",
        "test_input2 = torch.tensor(test_input2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "a70b4060",
      "metadata": {
        "id": "a70b4060",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49e68b93-db36-4811-bdb8-4da642be8783"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([    5,    51,    41,  3518,  2588,  8758,     4,   537,   258,   366,\n",
              "         3566,  2512,    28,    11,  8320,  1646,    83,   597,  8243,   627,\n",
              "           32,   160,    41,  8070,   537,   307,     6, 11778,   160,    38,\n",
              "           55,  3505,    41,  1520,  2588,  8758,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "test_input2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "731eada3",
      "metadata": {
        "id": "731eada3"
      },
      "outputs": [],
      "source": [
        "test_segment2 = torch.tensor([0]*7 + [1]*27 + [0]*27)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "91e51e33",
      "metadata": {
        "id": "91e51e33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b4c9cc7-44f1-48c8-a7de-4ac1fd55e001"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "test_segment2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "a12b2821",
      "metadata": {
        "id": "a12b2821"
      },
      "outputs": [],
      "source": [
        "test_inputs = torch.stack([test_input1,test_input2]*16,0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "cebdd00f",
      "metadata": {
        "id": "cebdd00f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0992c5f5-8148-41c1-9361-70e8b32f21da"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 5, 51, 97,  ...,  0,  0,  0],\n",
              "        [ 5, 51, 41,  ...,  0,  0,  0],\n",
              "        [ 5, 51, 97,  ...,  0,  0,  0],\n",
              "        ...,\n",
              "        [ 5, 51, 41,  ...,  0,  0,  0],\n",
              "        [ 5, 51, 97,  ...,  0,  0,  0],\n",
              "        [ 5, 51, 41,  ...,  0,  0,  0]])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "test_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "b2b078bf",
      "metadata": {
        "id": "b2b078bf"
      },
      "outputs": [],
      "source": [
        "test_segments = torch.stack([test_segment1,test_segment2]*16,0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "ee9cbd0e",
      "metadata": {
        "id": "ee9cbd0e"
      },
      "outputs": [],
      "source": [
        "test_inputs = test_inputs.to(config.device)\n",
        "test_segments = test_segments.to(config.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "513781df",
      "metadata": {
        "id": "513781df"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "# model = model.to(config.device)\n",
        "test_out = model(test_inputs,test_segments)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "33a930d0",
      "metadata": {
        "id": "33a930d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "920b9789-f712-442e-a93c-1829ddc371c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_sentence1\n",
            "MASK 예측 결과\n",
            "1. is\n",
            "2. what\n",
            "3. who\n",
            "4. when\n",
            "5. where\n"
          ]
        }
      ],
      "source": [
        "num = 1\n",
        "test_sentence = '[CLS] what are your hobbies [SEP] i have been watching and playing [MASK] more than ten years , so that both are my hobbies'\n",
        "\n",
        "print('test_sentence1')\n",
        "print('MASK 예측 결과')\n",
        "for j in [vocab.decode(i) for i in torch.topk(test_out[1][0][13],k=5)[1].cpu().detach().tolist()]:\n",
        "    print(f\"{num}. {j}\")\n",
        "    num += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "85db7242",
      "metadata": {
        "id": "85db7242",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c24362f-c717-4a4a-8b5c-0a3c5674f38f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_sentence2\n",
            "MASK 예측 결과\n",
            "1. is\n",
            "2. what\n",
            "3. who\n",
            "4. when\n",
            "5. where\n"
          ]
        }
      ],
      "source": [
        "num = 1\n",
        "print('test_sentence2')\n",
        "print('MASK 예측 결과')\n",
        "for j in [vocab.decode(i) for i in torch.topk(test_out[1][1][mask_idx2],k=5)[1].cpu().detach().tolist()]:\n",
        "    print(f\"{num}. {j}\")\n",
        "    num += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f1b8e8c",
      "metadata": {
        "id": "4f1b8e8c"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}